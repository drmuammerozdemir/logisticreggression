# ============================================================
# üî¨ Binary (Logistic) + Continuous (Linear) Regression Toolkit
# Univariate tarama + Multivariate model + (Binary) ROC‚ÄìAUC, Youden cut-off, DeLong testi, Firth lojistik
# ============================================================

import io
import math
import numpy as np
import pandas as pd
import streamlit as st

import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve
from statsmodels.stats.outliers_influence import variance_inflation_factor
from delong import delong_ci, delong_roc_test
from scipy.stats import norm

# G√∂rselle≈ütirme
import matplotlib.pyplot as plt

# SAV i√ßin
try:
    import pyreadstat
    HAS_PYREADSTAT = True
except Exception:
    HAS_PYREADSTAT = False

st.set_page_config(page_title="Regression + ROC Toolkit", layout="wide")
st.title("üßÆ Regression Toolkit: Logistic (ROC) + Linear")

# ===================== Yardƒ±mcƒ±lar ===================== #

def read_any(file):
    name = file.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(file)
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(file)
    if name.endswith(".sav"):
        if not HAS_PYREADSTAT:
            st.error(".sav dosyasƒ± i√ßin 'pyreadstat' gerekir. L√ºtfen 'pip install pyreadstat' kurun.")
            st.stop()
        try:
            file.seek(0)
            buffer = io.BytesIO(file.read())
            df, meta = pyreadstat.read_sav(buffer)
            return df
        except Exception:
            import tempfile, os
            try:
                file.seek(0)
                with tempfile.NamedTemporaryFile(delete=False, suffix=".sav") as tmp:
                    tmp.write(file.read())
                    tmp_path = tmp.name
                df, meta = pyreadstat.read_sav(tmp_path)
                os.unlink(tmp_path)
                return df
            except Exception as e2:
                st.error(f".sav okunamadƒ±: {e2}")
                st.stop()
    st.error("Desteklenmeyen dosya t√ºr√º. CSV/XLSX/SAV y√ºkleyin.")
    st.stop()

def format_or_ci(or_val, lo, hi):
    if any([pd.isna(or_val), pd.isna(lo), pd.isna(hi)]):
        return "NA"
    return f"{or_val:.3f} ({lo:.3f}‚Äì{hi:.3f})"

def build_formula(dv, predictors, cat_info):
    terms = []
    for v in predictors:
        if v in cat_info and cat_info[v] is not None:
            ref = cat_info[v]
            terms.append(f"C({v}, Treatment(reference='{ref}'))")
        else:
            terms.append(v)
    rhs = " + ".join(terms) if predictors else "1"
    return f"{dv} ~ {rhs}"

def fit_logit(formula, data):
    model = smf.logit(formula, data=data)
    res = model.fit(disp=0, maxiter=200)
    return model, res

def fit_ols(formula, data):
    model = smf.ols(formula, data=data)
    res = model.fit()
    return model, res

def extract_or_table(res):
    params = res.params
    conf = res.conf_int()
    conf.columns = ["ci_low", "ci_high"]
    pvals = res.pvalues
    out = pd.concat([params, conf, pvals], axis=1)
    out.columns = ["coef", "ci_low", "ci_high", "p"]
    out["OR"] = np.exp(out["coef"])
    out["OR_low"] = np.exp(out["ci_low"])
    out["OR_high"] = np.exp(out["ci_high"])
    return out.reset_index().rename(columns={"index": "variable"})

def make_confusion(y_true, y_prob, threshold=0.5):
    y_pred = (y_prob >= threshold).astype(int)
    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])
    tn, fp, fn, tp = cm.ravel()
    acc = (tp + tn) / cm.sum()
    sens = tp / (tp + fn) if (tp + fn) else np.nan
    spec = tn / (tn + fp) if (tn + fp) else np.nan
    prev = np.mean(y_true)
    ppv = (sens*prev) / (sens*prev + (1-spec)*(1-prev)) if not (np.isnan(sens) or np.isnan(spec)) else np.nan
    npv = (spec*(1-prev)) / ((1-sens)*prev + spec*(1-prev)) if not (np.isnan(sens) or np.isnan(spec)) else np.nan
    lr_pos = sens / (1-spec) if (1-spec) > 0 else np.nan
    lr_neg = (1-sens) / spec if spec > 0 else np.nan
    return cm, acc, sens, spec, ppv, npv, lr_pos, lr_neg

def compute_youden(fpr, tpr, thr):
    j = tpr - fpr
    idx = int(np.argmax(j))
    return {
        "threshold": float(thr[idx]),
        "J": float(j[idx]),
        "sens": float(tpr[idx]),
        "spec": float(1 - fpr[idx]),
        "index": idx
    }

def _wilson_ci(success, total, alpha=0.05):
    """ƒ∞kili orana Wilson (%95 GA) ‚Äî success/total i√ßin (lo, hi) d√∂ner."""
    if total == 0:
        return (np.nan, np.nan)
    p = success / total
    z = norm.ppf(1 - alpha/2)
    den = 1 + z**2/total
    center = (p + z**2/(2*total)) / den
    half = (z*np.sqrt(p*(1-p)/total + z**2/(4*total**2))) / den
    return max(0.0, center - half), min(1.0, center + half)

# ---- Unstable kontrol√º (u√ßuk/sonsuz CI vs.) ----
def _is_unstable(orv, lo, hi, fold_limit=1e6):
    if not (np.isfinite(orv) and np.isfinite(lo) and np.isfinite(hi)):
        return True
    if lo <= 0 or hi <= 0:
        return True
    if (hi / lo) > fold_limit:
        return True
    return False

# ---- Firth helpers ----
def _sigmoid(z):
    return 1.0 / (1.0 + np.exp(-z))

def firth_logit(X, y, names=None, maxiter=200, tol=1e-8):
    X = np.asarray(X, float)
    y = np.asarray(y, int)
    n, p = X.shape
    beta = np.zeros(p)

    converged = False
    for _ in range(maxiter):
        eta = X @ beta
        p_i = _sigmoid(eta)
        W = p_i * (1.0 - p_i)
        XWX = X.T @ (W[:, None] * X)
        try:
            XWX_inv = np.linalg.inv(XWX)
        except np.linalg.LinAlgError:
            XWX_inv = np.linalg.pinv(XWX)

        S = (X * W[:, None]) @ XWX_inv
        h = np.sum(S * X, axis=1)

        a = (0.5 - h) * (1.0 - 2.0 * p_i)
        Ustar = X.T @ (y - p_i + a)

        step = XWX_inv @ Ustar
        beta_new = beta + step

        if np.max(np.abs(step)) < tol:
            beta = beta_new
            converged = True
            break
        beta = beta_new

    eta = X @ beta
    p_i = _sigmoid(eta)
    W = p_i * (1.0 - p_i)
    XWX = X.T @ (W[:, None] * X)
    try:
        cov = np.linalg.inv(XWX)
    except np.linalg.LinAlgError:
        cov = np.linalg.pinv(XWX)
    se = np.sqrt(np.diag(cov))
    z = beta / se
    pvals = 2 * (1 - norm.cdf(np.abs(z)))
    zcrit = norm.ppf(0.975)
    ci_low = beta - zcrit * se
    ci_high = beta + zcrit * se

    return {
        "coef": beta, "se": se, "z": z, "p": pvals,
        "ci_low": ci_low, "ci_high": ci_high,
        "names": names if names is not None else [f"x{i}" for i in range(len(beta))],
        "converged": converged, "y_prob": p_i
    }

def firth_by_formula(formula, data):
    model = smf.logit(formula, data=data)
    X = model.exog
    y = model.endog
    names = model.exog_names
    return firth_logit(X, y, names=names)

def hosmer_lemeshow(y_true, y_prob, g=10):
    data = pd.DataFrame({"y": y_true, "p": y_prob}).sort_values("p").reset_index(drop=True)
    data["group"] = pd.qcut(data["p"], q=g, duplicates='drop')
    tbl = data.groupby("group").agg(n=("y", "size"), obs=("y", "sum"), p_mean=("p", "mean"))
    tbl["exp"] = tbl["n"] * tbl["p_mean"]
    tbl["chi"] = (tbl["obs"] - tbl["exp"])**2 / (tbl["exp"] * (1 - tbl["p_mean"]).clip(lower=1e-12))
    chi2 = tbl["chi"].sum()
    from scipy.stats import chi2 as chi2_dist
    df_hl = max(int(tbl.shape[0] - 2), 1)
    pval = 1 - chi2_dist.cdf(chi2, df_hl)
    return chi2, pval, tbl.reset_index()

def _clean_term_for_forest(t):
    # C(var)[T.level] ‚Üí var: level
    if isinstance(t, str) and t.startswith("C(") and ")[T." in t:
        base = t.split("C(")[1].split(")")[0]
        lev = t.split("[T.")[1].rstrip("]")
        return f"{base}: {lev}"
    return t

def make_forest_plot_linear(df_or, title="Forest Plot (OR, 95% CI)"):
    """
    df_or s√ºtunlarƒ±: ['label','OR','OR_low','OR_high','p']
    Lineer x-ekseni (√∂r. 0-2), kalƒ±n dikey √ßizgi (OR=1)
    """
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd

    df = df_or.replace([np.inf, -np.inf], np.nan).dropna(subset=["OR","OR_low","OR_high"]).copy()
    if df.empty:
        return None

    df = df.sort_values("OR", ascending=True).reset_index(drop=True)
    y = np.arange(len(df))

    fig, ax = plt.subplots(figsize=(7, max(3.2, 0.55*len(df)+1)))

    # CI √ßizgileri ve marker
    for i, r in df.iterrows():
        ax.plot([r["OR_low"], r["OR_high"]], [y[i], y[i]], color="black", lw=2.5)
        ax.scatter(r["OR"], y[i], color="black", s=50, marker="s", zorder=3)

    # OR=1 kalƒ±n dikey √ßizgi
    ax.axvline(1, color="black", lw=2)

    # Y ekseni
    ax.set_yticks(y)
    ax.set_yticklabels(df["label"], fontsize=11)
    ax.invert_yaxis()
    ax.set_xlabel("Odds Ratio", fontsize=11)
    ax.set_title(title, fontsize=13, pad=10)
    ax.set_xlim(0.4, 2.0)
    ax.grid(False)

    # Saƒü tarafa metin s√ºtunu: OR (95% CI) ve p
    ax2 = ax.twinx()
    ax2.set_ylim(ax.get_ylim())
    ax2.set_yticks(y)
    texts = []
    for _, r in df.iterrows():
        ci_txt = f"{r['OR']:.3f} ({r['OR_low']:.3f}-{r['OR_high']:.3f})"
        ptxt = ""
        if "p" in r and pd.notna(r["p"]):
            ptxt = "<0.001" if r["p"] < 0.001 else f"{r['p']:.3f}"
        texts.append(f"{ci_txt}    {ptxt}")
    ax2.set_yticklabels(texts, fontsize=11)
    ax2.tick_params(axis="y", length=0)
    ax2.set_ylabel("")

    plt.tight_layout()
    return fig

# ===================== 1) Veri Y√ºkleme ===================== #

st.sidebar.header("1) Veri Y√ºkle")
file = st.sidebar.file_uploader("CSV / XLSX / SAV y√ºkleyin", type=["csv", "xlsx", "xls", "sav"])
if not file:
    st.info("Ba≈ülamak i√ßin bir veri dosyasƒ± y√ºkleyin.")
    st.stop()
df = read_any(file)
st.write("**√ñrnek ƒ∞lk Satƒ±rlar:**")
st.dataframe(df.head())

# ===================== 2) Model Tipi ve Deƒüi≈üken Se√ßimi ===================== #

st.sidebar.header("2) Model Tipi")
mode = st.sidebar.selectbox("Se√ßin", ["Binary (Logistic)", "Continuous (Linear)"])

all_cols = df.columns.tolist()

if mode == "Binary (Logistic)":
    # DV se√ßimi
    dv = st.sidebar.selectbox("Baƒüƒ±mlƒ± Deƒüi≈üken (Binary)", options=all_cols)
    unique_vals = df[dv].dropna().unique().tolist()
    map_needed = not (set(unique_vals) <= {0, 1})
    if map_needed:
        st.sidebar.markdown("**Pozitif sƒ±nƒ±fƒ± se√ßin (1):**")
        pos_label = st.sidebar.selectbox("Pozitif sƒ±nƒ±f (1)", options=sorted(unique_vals, key=str))
        df["__DV__"] = (df[dv] == pos_label).astype(int)
        dv_use = "__DV__"
        st.sidebar.caption(f"Se√ßilen pozitif: {pos_label} ‚Üí 1, diƒüerleri ‚Üí 0")
    else:
        dv_use = dv

    candidates = [c for c in all_cols if c != dv]
    ivs = st.sidebar.multiselect("Aday Baƒüƒ±msƒ±z Deƒüi≈ükenler", options=candidates, default=candidates)
    if not ivs:
        st.warning("En az bir baƒüƒ±msƒ±z deƒüi≈üken se√ßin.")
        st.stop()

    # Kategorikler
    st.sidebar.header("3) Kategorik Tanƒ±mlarƒ±")
    cat_vars = st.sidebar.multiselect(
        "Kategorik deƒüi≈ükenler (varsa)",
        options=ivs,
        default=[c for c in ivs if df[c].dtype == 'object']
    )
    cat_ref = {}
    for c in cat_vars:
        levels = sorted([str(x) for x in pd.Series(df[c]).dropna().unique()])
        ref = st.sidebar.selectbox(f"Referans ‚Äì {c}", options=levels, index=0, key=f"ref_{c}")
        cat_ref[c] = ref

    use_cols = [dv_use] + ivs
    work = df[use_cols].copy()
    # numerik d√∂n√º≈üt√ºr
    for c in ivs:
        if c not in cat_vars:
            work[c] = pd.to_numeric(work[c], errors='coerce')
    n_before = work.shape[0]
    work = work.dropna()
    n_after = work.shape[0]
    st.sidebar.caption(f"Eksik nedeniyle d√º≈üen g√∂zlem: {n_before - n_after}")

        # ---------- Univariate ---------- #
    st.header("üîπ Univariate Logistic Regression")
    uni_rows = []
    for var in ivs:
        try:
            fml = build_formula(dv_use, [var], cat_info=cat_ref)
            _, res = fit_logit(fml, work)

            tab = extract_or_table(res)
            rows = tab[~tab["variable"].str.contains("Intercept", case=False, na=False)].copy()
            p_display = rows["p"].min() if rows.shape[0] > 0 else np.nan

            if rows.shape[0] == 1:
                # Tek katsayƒ± ‚Üí OR/CI hesapla
                OR = rows["OR"].iloc[0]
                lo = rows["OR_low"].iloc[0]
                hi = rows["OR_high"].iloc[0]

                # ===== MINI FIRTH FALLBACK (yalnƒ±zca patlayan/sonsuz/√ßok geni≈ü CI'da) =====
                if _is_unstable(OR, lo, hi):
                    try:
                        fr_uni = firth_by_formula(fml, work)
                        mask = [not str(nm).lower().startswith("intercept") for nm in fr_uni["names"]]
                        b, lo_b, hi_b = fr_uni["coef"][mask][0], fr_uni["ci_low"][mask][0], fr_uni["ci_high"][mask][0]
                        or_str = f"{np.exp(b):.3f} ({np.exp(lo_b):.3f}‚Äì{np.exp(hi_b):.3f}) [Firth]"
                    except Exception:
                        # Firth de ba≈üarƒ±sƒ±zsa "NE" yaz
                        or_str = "NE (unstable/separation)"
                else:
                    # Stabil ise klasik Wald OR(CI)
                    or_str = f"{OR:.3f} ({lo:.3f}‚Äì{hi:.3f})"
            else:
                # √áok d√ºzeyli kategorik: tek OR yok ‚Üí "NA"
                or_str = "NA"

            uni_rows.append({
                "deƒüi≈üken": var,
                "OR (95% GA)": or_str,
                "p": p_display,
                "AIC": res.aic,
                "BIC": res.bic
            })

        except Exception:
            uni_rows.append({"deƒüi≈üken": var, "OR (95% GA)": "NA", "p": np.nan, "AIC": np.nan, "BIC": np.nan})

    uni_df = pd.DataFrame(uni_rows).sort_values("p", na_position='last')
    st.dataframe(uni_df, use_container_width=True)
    st.download_button(
        "Univariate (CSV)",
        uni_df.to_csv(index=False).encode("utf-8"),
        file_name="univariate_logit.csv",
        mime="text/csv"
    )

    # Aday se√ßimi
    st.subheader("Univariate'e g√∂re Multivariate aday se√ßimi")
    p_thresh = st.slider("p-e≈üiƒüi", 0.001, 0.20, 0.05, 0.001)
    preselect = uni_df.loc[uni_df["p"] <= p_thresh, "deƒüi≈üken"].tolist()
    st.caption(f"E≈üik altƒ±: {', '.join(preselect) if preselect else '(yok)'}")
    manual_multi = st.multiselect("Multivariate deƒüi≈ükenleri", options=ivs, default=preselect)

    # ---------- Multivariate + ROC ---------- #
    st.header("üîπ Multivariate Logistic + ROC")
    if manual_multi:
        fml_multi = build_formula(dv_use, manual_multi, cat_ref)
        with st.expander("Kullanƒ±lan form√ºl"):
            st.code(fml_multi)
        try:
            model_m, res_m = fit_logit(fml_multi, work)

            # Katsayƒ±lar
            multi_tab = extract_or_table(res_m)
            multi_tab["OR (95% GA)"] = multi_tab.apply(
                lambda r: format_or_ci(np.exp(r["coef"]), np.exp(r["ci_low"]), np.exp(r["ci_high"]))
                if pd.notna(r["coef"]) else "NA", axis=1
            )
            pretty = multi_tab[["variable", "OR (95% GA)", "p"]].copy()
            st.subheader("Model Katsayƒ±larƒ±")
            st.dataframe(pretty, use_container_width=True)

            # === Forest plot (Multivariate OR, 95% CI, linear scale) ===
            forest_df = multi_tab.copy()
            forest_df = forest_df[~forest_df["variable"].str.contains("Intercept", case=False, na=False)].copy()

            def _clean_term_for_forest(t):
                if isinstance(t, str) and t.startswith("C(") and ")[T." in t:
                    base = t.split("C(")[1].split(")")[0]
                    lev = t.split("[T.")[1].rstrip("]")
                    return f"{base}: {lev}"
                return t

            forest_df["label"] = forest_df["variable"].map(_clean_term_for_forest)
            forest_df = forest_df.assign(
                OR=forest_df["OR"].astype(float),
                OR_low=forest_df["OR_low"].astype(float),
                OR_high=forest_df["OR_high"].astype(float),
                p=multi_tab.set_index("variable")["p"].reindex(forest_df["variable"]).values
            )[["label","OR","OR_low","OR_high","p"]]

            fig_forest = make_forest_plot_linear(forest_df, title="Multivariate OR (95% CI)")
            if fig_forest is not None:
                st.pyplot(fig_forest, use_container_width=True)
            else:
                st.info("Forest plot i√ßin uygun (sonlu) OR ve g√ºven aralƒ±ƒüƒ± bulunamadƒ±.")

            # AIC/BIC, McFadden R¬≤
            llf = res_m.llf
            llnull = res_m.llnull if hasattr(res_m, 'llnull') else np.nan
            pseudo_r2 = 1 - (llf / llnull) if not (np.isnan(llf) or np.isnan(llnull)) else np.nan
            c1, c2, c3 = st.columns(3)
            c1.metric("AIC", f"{res_m.aic:.2f}")
            c2.metric("BIC", f"{res_m.bic:.2f}")
            c3.metric("McFadden R¬≤", f"{pseudo_r2:.3f}" if not pd.isna(pseudo_r2) else "NA")

            # Tahminler
            y_true = work[dv_use].astype(int).values
            y_prob = res_m.predict()

            # HL
            chi_hl, p_hl, tbl_hl = hosmer_lemeshow(y_true, y_prob, g=10)
            st.write(f"**Hosmer‚ÄìLemeshow**: œá¬≤ = {chi_hl:.3f}, p = {p_hl:.3f}")
            with st.expander("HL Grup Tablosu"):
                st.dataframe(tbl_hl)

            # ===== VIF (multicollinearity) =====
            try:
                exog = res_m.model.exog
                names = res_m.model.exog_names
                vif_rows = []
                for i, nm in enumerate(names):
                    if nm.lower().startswith("intercept"):
                        continue
                    try:
                        vif_val = variance_inflation_factor(exog, i)
                        vif_rows.append({"Variable": nm, "VIF": float(vif_val), "Tolerance": float(1.0/vif_val)})
                    except Exception:
                        vif_rows.append({"Variable": nm, "VIF": np.nan, "Tolerance": np.nan})
                vif_df = pd.DataFrame(vif_rows).sort_values("VIF", na_position="last")
                def _style_vif(v):
                    try:
                        return "font-weight:bold;" if float(v) > 5 else ""
                    except:
                        return ""
                st.subheader("üìé Kolinearite Kontrol√º (VIF)")
                st.dataframe(vif_df.style.applymap(_style_vif, subset=["VIF"]), use_container_width=True)
                st.caption("Not: VIF>5 (bazƒ± kƒ±lavuzlarda >10) y√ºksek kolinearite olarak yorumlanƒ±r.")
                st.download_button("VIF (CSV)", vif_df.to_csv(index=False).encode("utf-8"),
                                   file_name="vif_model1.csv", mime="text/csv")
            except Exception as e:
                st.warning(f"VIF hesaplanamadƒ±: {e}")

            # ROC (tek kere)
            fpr, tpr, thr = roc_curve(y_true, y_prob)
            auc = roc_auc_score(y_true, y_prob)
            st.write(f"**ROC AUC**: {auc:.3f}")
            fig = plt.figure()
            plt.plot(fpr, tpr, label=f"AUC={auc:.3f}")
            plt.plot([0, 1], [0, 1], linestyle='--')
            plt.xlabel('1 - Specificity (FPR)')
            plt.ylabel('Sensitivity (TPR)')
            plt.title('ROC Curve')
            plt.legend(loc="lower right")
            st.pyplot(fig, use_container_width=True)

            # === ROC Altƒ± √ñzet Tablo (AUC CI, p; Youden cut-off; Sens/Spec/PPV/NPV + %95 GA) ===
            # AUC i√ßin DeLong CI ve p (H0: AUC=0.5)
            auc_m, lo_auc, hi_auc, se_auc = delong_ci(y_true, y_prob)
            z_auc = (auc_m - 0.5) / se_auc if se_auc > 0 else np.nan
            p_auc = 2 * (1 - norm.cdf(abs(z_auc))) if np.isfinite(z_auc) else np.nan

            # Youden‚Äôa g√∂re en iyi kesim ve o kesimde karƒ±≈üƒ±klƒ±k matrisi
            best = compute_youden(fpr, tpr, thr)
            cut_for_table = float(np.clip(best["threshold"], 0.0, 1.0))
            y_pred_cut = (y_prob >= cut_for_table).astype(int)
            tn, fp, fn, tp = confusion_matrix(y_true, y_pred_cut, labels=[0,1]).ravel()

            # Oranlar ve Wilson %95 GA
            sens = tp / (tp + fn) if (tp + fn) else np.nan
            spec = tn / (tn + fp) if (tn + fp) else np.nan
            ppv  = tp / (tp + fp) if (tp + fp) else np.nan
            npv  = tn / (tn + fn) if (tn + fn) else np.nan

            sens_lo, sens_hi = _wilson_ci(tp, tp + fn)
            spec_lo, spec_hi = _wilson_ci(tn, tn + fp)
            ppv_lo,  ppv_hi  = _wilson_ci(tp, tp + fp) if (tp + fp) else (np.nan, np.nan)
            npv_lo,  npv_hi  = _wilson_ci(tn, tn + fn) if (tn + fn) else (np.nan, np.nan)

            # G√∂rsel tablo (y√ºzdeleri resimdeki gibi tam sayƒ±ya yuvarlayarak)
            summary_rows = [
                ("AUC (95% CI)",          f"{auc_m:.3f} ({lo_auc:.3f}‚Äì{hi_auc:.3f})"),
                ("p-Value",               "<0.001" if (pd.notna(p_auc) and p_auc < 0.001) else f"{p_auc:.4f}"),
                ("Cut-off",               f"‚â• {cut_for_table:.2g}"),
                ("Sensitivity (95% CI)",  f"{sens*100:.0f} ({sens_lo*100:.1f}‚Äì{sens_hi*100:.1f})"),
                ("Specificity (95% CI)",  f"{spec*100:.0f} ({spec_lo*100:.1f}‚Äì{spec_hi*100:.1f})"),
                ("PPV (95% CI)",          f"{ppv*100:.0f} ({ppv_lo*100:.1f}‚Äì{ppv_hi*100:.1f})" if pd.notna(ppv) else "NA"),
                ("NPV (95% CI)",          f"{npv*100:.0f} ({npv_lo*100:.1f}‚Äì{npv_hi*100:.1f})" if pd.notna(npv) else "NA"),
            ]
            roc_summary_df = pd.DataFrame(summary_rows, columns=["Metric", "Value"])
            st.dataframe(roc_summary_df, use_container_width=True)


            # ===== Firth bias-reduced logistic (opsiyonel) =====
            st.subheader("üõ°Ô∏è Firth (bias-reduced) Lojistik ‚Äì Ayrƒ±≈ümaya dayanƒ±klƒ±")
            use_firth = st.checkbox("Model 1'i Firth ile yeniden tahmin et", value=False)
            if use_firth:
                try:
                    fr = firth_by_formula(fml_multi, work)
                    fnames = fr["names"]

                    rows_f = []
                    for nm, b, lo_b, hi_b, p_b in zip(
                        fnames, fr["coef"], fr["ci_low"], fr["ci_high"], fr["p"]
                    ):
                        if str(nm).lower().startswith("intercept"):
                            continue
                        ORb, Lb, Hb = np.exp(b), np.exp(lo_b), np.exp(hi_b)
                        rows_f.append({
                            "variable": nm,
                            "OR (95% GA)": f"{ORb:.3f} ({Lb:.3f}‚Äì{Hb:.3f})",
                            "p": "<0.001" if p_b < 0.001 else f"{p_b:.3f}"
                        })
                    firth_df = pd.DataFrame(rows_f)
                    st.dataframe(firth_df, use_container_width=True)
                    st.caption("Not: Firth, separation durumlarƒ±nda stabil OR/GA √ºretir (Jeffreys prior).")

                    # ROC kƒ±yasƒ±
                    fpr_f, tpr_f, thr_f = roc_curve(y_true, fr["y_prob"])
                    auc_f = roc_auc_score(y_true, fr["y_prob"])
                    fig_f = plt.figure()
                    plt.plot(fpr, tpr, label=f"Klasik Model 1 (AUC={auc:.3f})")
                    plt.plot(fpr_f, tpr_f, label=f"Firth Model 1 (AUC={auc_f:.3f})")
                    plt.plot([0, 1], [0, 1], '--')
                    plt.xlabel('1 - Specificity (FPR)'); plt.ylabel('Sensitivity (TPR)')
                    plt.title('ROC: Klasik vs Firth')
                    plt.legend(loc="lower right")
                    st.pyplot(fig_f, use_container_width=True)

                except Exception as e:
                    st.error(f"Firth hesaplanamadƒ±: {e}")

            # ==== DeLong Kar≈üƒ±la≈ütƒ±rma (Model vs Tek Belirte√ß / ƒ∞ki Skor) ====
            st.subheader("ROC Kar≈üƒ±la≈ütƒ±rma (DeLong)")
            num_cols = [c for c in work.columns if c != dv_use and np.issubdtype(work[c].dtype, np.number)]
            compare_var = st.selectbox(
                "Kar≈üƒ±la≈ütƒ±rƒ±lacak ikinci skor/deƒüi≈üken (√∂rn. TRP, 3OHKYN):",
                options=num_cols
            )
            if compare_var:
                try:
                    y2 = pd.to_numeric(work[compare_var], errors="coerce").values
                    mask = ~np.isnan(y2)
                    y_true_cmp = y_true[mask]
                    y_prob_cmp = y_prob[mask]
                    y2_cmp = y2[mask]

                    auc_m, lo_m, hi_m, se_m = delong_ci(y_true_cmp, y_prob_cmp)
                    auc_x, lo_x, hi_x, se_x = delong_ci(y_true_cmp, y2_cmp)
                    res = delong_roc_test(y_true_cmp, y_prob_cmp, y2_cmp)

                    st.write(f"**Model (Predicted Probability)**: AUC={auc_m:.3f} (95% GA {lo_m:.3f}‚Äì{hi_m:.3f})")
                    st.write(f"**{compare_var}**: AUC={auc_x:.3f} (95% GA {lo_x:.3f}‚Äì{hi_x:.3f})")
                    st.success(f"**DeLong testi**: z={res['z']:.3f}, p={res['p']:.4f} ‚Üí (H‚ÇÄ: AUC'ler e≈üit)")
                except Exception as e:
                    st.error(f"DeLong hesaplanamadƒ±: {e}")

            # ROC Koordinatlarƒ± CSV
            roc_df = pd.DataFrame({
                "threshold": thr,
                "sensitivity": tpr,
                "fpr": fpr,
                "specificity": 1 - fpr,
                "youden_J": tpr - fpr
            })
            st.download_button(
                "ROC Koordinatlarƒ± (CSV)",
                roc_df.to_csv(index=False).encode("utf-8"),
                file_name="roc_coords.csv",
                mime="text/csv"
            )

            # Youden cut-off
            best = compute_youden(fpr, tpr, thr)
            st.success(
                f"**Youden en iyi cut-off** = {best['threshold']:.4f} | "
                f"Sens={best['sens']:.3f}, Spec={best['spec']:.3f}, J={best['J']:.3f}"
            )

            # Cut-off deƒüerlendirme
            st.subheader("Cut-off Deƒüerlendirme")
            cut_default = float(np.clip(best["threshold"], 0.0, 1.0))
            cut = st.slider("Cut-off (Youden varsayƒ±lan)", 0.0, 1.0, cut_default, 0.01)
            cm, acc, sens, spec, ppv, npv, lrpos, lrneg = make_confusion(y_true, y_prob, threshold=cut)
            st.write(pd.DataFrame(cm, index=["Ger√ßek 0", "Ger√ßek 1"], columns=["Tahmin 0", "Tahmin 1"]))

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Accuracy", f"{acc:.3f}")
            c2.metric("Sensitivity", f"{sens:.3f}")
            c3.metric("Specificity", f"{spec:.3f}")
            c4.metric("PPV / NPV", f"{ppv:.3f} / {npv:.3f}")
            c5, c6 = st.columns(2)
            c5.metric("LR+", f"{lrpos:.3f}" if not pd.isna(lrpos) else "NA")
            c6.metric("LR‚àí", f"{lrneg:.3f}" if not pd.isna(lrneg) else "NA")

            # ƒ∞ndir
            st.download_button(
                "Multivariate (CSV)",
                pretty.to_csv(index=False).encode("utf-8"),
                file_name="multivariate_logit.csv",
                mime="text/csv"
            )

            # ================== Yayƒ±n Formatƒ± √ñzet Tablo (Uni + Multi) ==================
            st.subheader("üìã √ñzet Tablo (Univariate + Multivariate)")

            def fmt_p(p):
                if pd.isna(p):
                    return ""
                try:
                    return "<0.001" if p < 0.001 else f"{p:.3f}"
                except Exception:
                    return str(p)

            multi_raw = res_m.summary2().tables[1].reset_index().rename(columns={"index": "term"})
            ci_m = res_m.conf_int()
            ci_m.columns = ["ci_low", "ci_high"]
            multi_raw = multi_raw.merge(ci_m, left_on="term", right_index=True, how="left")
            multi_raw["OR"] = np.exp(multi_raw["Coef."])
            multi_raw["OR_low"] = np.exp(multi_raw["ci_low"])
            multi_raw["OR_high"] = np.exp(multi_raw["ci_high"])
            multi_raw = multi_raw[~multi_raw["term"].str.contains("Intercept", case=False, na=False)].copy()

            def clean_term(t):
                if t.startswith("C(") and ")[T." in t:
                    base = t.split("C(")[1].split(")")[0]
                    lev = t.split("[T.")[1].rstrip("]")
                    return f"{base}: {lev}"
                return t

            multi_raw["clean"] = multi_raw["term"].map(clean_term)
            multi_map_or = dict(zip(
                multi_raw["clean"],
                [f"{o:.3f} ({lo:.3f}‚Äì{hi:.3f})" for o, lo, hi in zip(multi_raw["OR"], multi_raw["OR_low"], multi_raw["OR_high"])]
            ))
            multi_map_p = dict(zip(multi_raw["clean"], multi_raw["P>|z|"]))

            # Univariate √∂zetinden √ßek
            uni_tmp = uni_df[["deƒüi≈üken", "OR (95% GA)", "p"]].copy()
            uni_tmp.rename(columns={"deƒüi≈üken": "Variable",
                                    "OR (95% GA)": "Univariate OR (95% CI)",
                                    "p": "Univariate P"}, inplace=True)

            st.caption("ƒ∞steƒüe baƒülƒ±: bir deƒüi≈ükeni √∂l√ßekleyerek (√∂rn. SII/100) ek satƒ±r olu≈ütur.")
            add_scaled = st.checkbox("√ñl√ßekli satƒ±r ekle (√∂rn. SII/100)", value=False)
            if add_scaled:
                scale_var = st.selectbox("√ñl√ßeklenecek deƒüi≈üken", options=uni_tmp["Variable"].tolist())
                scale_val = st.number_input("√ñl√ßek katsayƒ±sƒ± (√∂rn. 100 ‚Üí SII/100)", min_value=1.0, value=100.0, step=1.0)
                r = uni_tmp.loc[uni_tmp["Variable"] == scale_var].copy()
                if not r.empty:
                    r = r.assign(Variable=scale_var + f" / {int(scale_val)}")
                    uni_tmp = pd.concat([uni_tmp, r], ignore_index=True)

            def take_multi_or(name):
                return multi_map_or.get(name, "/")

            def take_multi_p(name):
                p = multi_map_p.get(name, np.nan)
                return fmt_p(p) if not pd.isna(p) else "/"

            out = uni_tmp.copy()
            out["Multivariate OR (95% CI)"] = out["Variable"].map(take_multi_or)
            out["Multivariate P"] = out["Variable"].map(take_multi_p)
            out["Univariate P"] = out["Univariate P"].apply(fmt_p)

            out = out[["Variable",
                       "Univariate OR (95% CI)", "Univariate P",
                       "Multivariate OR (95% CI)", "Multivariate P"]]

            def highlight_sig(s):
                try:
                    val = s.replace("<", "")
                    return float(val) < 0.05
                except Exception:
                    return False

            styler = out.style.format(na_rep="").applymap(
                lambda v: "font-weight:bold;" if isinstance(v, str) and highlight_sig(v) else "",
                subset=["Univariate P", "Multivariate P"]
            )
            st.dataframe(styler, use_container_width=True)

            st.download_button(
                "√ñzet Tablo (CSV)",
                out.to_csv(index=False).encode("utf-8"),
                file_name="summary_uni_multi.csv",
                mime="text/csv"
            )
            # Excel (xlsxwriter gerekli)
            import io as _io
            buf = _io.BytesIO()
            with pd.ExcelWriter(buf, engine="xlsxwriter") as writer:
                out.to_excel(writer, sheet_name="Summary", index=False)
            st.download_button(
                "√ñzet Tablo (XLSX)",
                data=buf.getvalue(),
                file_name="summary_uni_multi.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            with st.expander("Statsmodels √∂zet"):
                st.text(res_m.summary2().as_text())

        except Exception as e:
            st.error(f"Model kurulumunda hata: {e}")
    else:
        st.info("Multivariate i√ßin en az bir deƒüi≈üken se√ßin.")

else:
    # --------- LINEAR (CONTINUOUS) --------- #
    dv = st.sidebar.selectbox("Baƒüƒ±mlƒ± Deƒüi≈üken (Continuous)", options=all_cols)
    candidates = [c for c in all_cols if c != dv]
    ivs = st.sidebar.multiselect("Aday Baƒüƒ±msƒ±z Deƒüi≈ükenler", options=candidates, default=candidates)
    if not ivs:
        st.warning("En az bir baƒüƒ±msƒ±z deƒüi≈üken se√ßin.")
        st.stop()

    # Kategorikler
    st.sidebar.header("3) Kategorik Tanƒ±mlarƒ±")
    cat_vars = st.sidebar.multiselect(
        "Kategorik (varsa)",
        options=ivs,
        default=[c for c in ivs if df[c].dtype == 'object']
    )
    cat_ref = {}
    for c in cat_vars:
        levels = sorted([str(x) for x in pd.Series(df[c]).dropna().unique()])
        ref = st.sidebar.selectbox(f"Referans ‚Äì {c}", options=levels, index=0, key=f"lin_ref_{c}")
        cat_ref[c] = ref

    use_cols = [dv] + ivs
    work = df[use_cols].copy()
    for c in [dv] + [x for x in ivs if x not in cat_vars]:
        work[c] = pd.to_numeric(work[c], errors='coerce')
    n_before = work.shape[0]
    work = work.dropna()
    n_after = work.shape[0]
    st.sidebar.caption(f"Eksik nedeniyle d√º≈üen g√∂zlem: {n_before - n_after}")

    # Univariate OLS
    st.header("üîπ Univariate Linear Regression")
    uni_rows = []
    for var in ivs:
        try:
            fml = build_formula(dv, [var], cat_info=cat_ref)
            _, res = fit_ols(fml, work)
            coef = res.params[1] if len(res.params) > 1 else np.nan
            ci = res.conf_int()
            lo = ci.iloc[1, 0] if ci.shape[0] > 1 else np.nan
            hi = ci.iloc[1, 1] if ci.shape[0] > 1 else np.nan
            p = res.pvalues[1] if len(res.pvalues) > 1 else np.nan
            uni_rows.append({
                "deƒüi≈üken": var,
                "Œ≤ (95% GA)": f"{coef:.3f} ({lo:.3f}‚Äì{hi:.3f})" if not pd.isna(coef) else "NA",
                "p": p,
                "R¬≤": res.rsquared,
                "AIC": res.aic,
                "BIC": res.bic
            })
        except Exception:
            uni_rows.append({"deƒüi≈üken": var, "Œ≤ (95% GA)": "NA", "p": np.nan, "R¬≤": np.nan, "AIC": np.nan, "BIC": np.nan})
    uni_df = pd.DataFrame(uni_rows).sort_values("p", na_position='last')
    st.dataframe(uni_df, use_container_width=True)
    st.download_button(
        "Univariate OLS (CSV)",
        uni_df.to_csv(index=False).encode("utf-8"),
        file_name="univariate_ols.csv",
        mime="text/csv"
    )

    # Multivariate OLS
    st.header("üîπ Multivariate Linear Regression")
    p_thresh = st.slider("p-e≈üiƒüi (Univariate ‚Üí √∂n se√ßim)", 0.001, 0.20, 0.05, 0.001, key="lin_p")
    preselect = uni_df.loc[uni_df["p"] <= p_thresh, "deƒüi≈üken"].tolist()
    st.caption(f"E≈üik altƒ±: {', '.join(preselect) if preselect else '(yok)'}")
    manual_multi = st.multiselect("Multivariate deƒüi≈ükenleri", options=ivs, default=preselect, key="lin_multi")

    if manual_multi:
        fml = build_formula(dv, manual_multi, cat_ref)
        with st.expander("Kullanƒ±lan form√ºl"):
            st.code(fml)
        try:
            model, res = fit_ols(fml, work)
            summ = res.summary2().tables[1].reset_index().rename(columns={"index": "variable"})
            ci = res.conf_int()
            ci.columns = ["ci_low", "ci_high"]
            summ = summ.merge(ci, left_on="variable", right_index=True, how="left")
            summ["Œ≤ (95% GA)"] = summ.apply(
                lambda r: f"{r['Coef.']:.3f} ({r['ci_low']:.3f}‚Äì{r['ci_high']:.3f})" if pd.notna(r["Coef."]) else "NA", axis=1
            )
            pretty = summ[["variable", "Œ≤ (95% GA)", "P>|t|"]]
            st.subheader("Model Katsayƒ±larƒ±")
            st.dataframe(pretty, use_container_width=True)

            c1, c2, c3 = st.columns(3)
            c1.metric("R¬≤ / Adj-R¬≤", f"{res.rsquared:.3f} / {res.rsquared_adj:.3f}")
            c2.metric("AIC", f"{res.aic:.2f}")
            c3.metric("BIC", f"{res.bic:.2f}")

            # Artƒ±k grafikleri
            st.subheader("Artƒ±k (Residual) ƒ∞nceleme")
            fitted = res.fittedvalues
            resid = res.resid
            fig1 = plt.figure()
            plt.scatter(fitted, resid)
            plt.axhline(0, linestyle='--')
            plt.xlabel("Fitted")
            plt.ylabel("Residuals")
            plt.title("Residuals vs Fitted")
            st.pyplot(fig1, use_container_width=True)

            from statsmodels.graphics.gofplots import qqplot
            fig2 = plt.figure()
            qqplot(resid, line='s', ax=plt.gca())
            plt.title("QQ Plot (Residuals)")
            st.pyplot(fig2, use_container_width=True)

        except Exception as e:
            st.error(f"Linear model hatasƒ±: {e}")
    else:
        st.info("Multivariate i√ßin en az bir deƒüi≈üken se√ßin.")

# ===================== Raporlama ƒ∞pu√ßlarƒ± ===================== #
st.markdown(
"""
---
**Raporlama notlarƒ±:**
- **Binary (Logistic):** Univariate ve Multivariate i√ßin OR, %95 GA, p; HL testi; ROC AUC; **Youden cut-off** ve o kesimde Sens/Spec/PPV/NPV/LR¬±; **DeLong testi** ile AUC farkƒ±; gerekirse **Firth** ile stabil sonu√ß.
- **Linear (OLS):** Œ≤, %95 GA, p; R¬≤/Adj-R¬≤; AIC/BIC; residual incelemeleri.
- Kategorik deƒüi≈ükenlerde **referans kategori**yi belirtmeyi unutmayƒ±n.
"""
)
